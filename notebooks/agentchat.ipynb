{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In the code in this block, replace\n",
    "- [YOUR OPENAI API KEY HERE] with an OpenAI API key and\n",
    "- [YOUR PROMPT HERE] with the request you're making to the AI assistent.\n",
    "\n",
    "Make sure to remove your API key before committing changes to this file.\n",
    "\n",
    "The assistents can reason about your prompt, write code to help solve it,\n",
    "execute that code, read and write files from / to the /notebooks/coding/\n",
    "folder, and install python dependencies from pip. However, the AI\n",
    "assistent can't execute the code it writes and the executive assistent\n",
    "isn't an AI, so it cannot write code.\n",
    "\n",
    "The AI assistent will prompt you before allowing the executive assistent\n",
    "to execute any code suggestions, giving you a chance to correct mistakes\n",
    "or change the objective.\n",
    "- Leave the prompt empty and press \"enter,\":\n",
    "  The executive assistent will scan the AI assistent's reply for code and\n",
    "  attempt to execute all the code it finds.\n",
    "- Type TERMINATE:\n",
    "  The session will end with no further AI assistence.\n",
    "- Write out further instructions for the AI assistent:\n",
    "  The AI assistent will generate a new response based on your input.\n",
    "\n",
    "Further instructions are often necessary when the AI assistent assumes\n",
    "you will gather information for it. Sometimes you can redirect the AI to\n",
    "instead generate code that the executive assistent can execute in order\n",
    "to gather that information automatically. If the task is too complex,\n",
    "such as estimating the value of a private company based on web search\n",
    "results, the AI assistent will only generate a very basic code template\n",
    "and ask you to do the rest. \n",
    "\n",
    "When ready, click \"Run All,\" above.\n",
    "\"\"\"\n",
    "\n",
    "API_KEY = \"[YOUR OPENAI API KEY HERE]\"\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "[YOUR PROMPT HERE]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_PROMPT = \"\"\"\n",
    "\n",
    "When writing code with visuals, such as plots, those visuals need\n",
    "to be written to local files.\n",
    "\n",
    "Start shell code blocks with \"```sh\" and python code blocks with \"```python\".\n",
    "\n",
    "Steps you should take when gathering data:\n",
    "1. Write code to install all necessary libraries.\n",
    "2. Write code to download the data to a file and print the first 100 bytes of data.\n",
    "   Look for indications of errors in the first 100 bytes.\n",
    "3. Write code to read the file and print its schema to the screen, using\n",
    "   the genson library.\n",
    "4. Continue resolving the primary request.\n",
    "You must ask me to execute the code after each step. Do not combine steps in a single\n",
    "reply. Use one reply per step. Check the size of any data before printing it to the\n",
    "screen. If it's larger than 1024 bytes, ask for confirmation before printing.\n",
    "\"\"\"\n",
    "\n",
    "import autogen\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': API_KEY,\n",
    "    },\n",
    "]\n",
    "\n",
    "# create an AssistantAgent named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config={\n",
    "        \"seed\": 42,  # seed for caching and reproducibility\n",
    "        \"config_list\": config_list,  # a list of OpenAI API configurations\n",
    "        \"temperature\": 0,  # temperature for sampling\n",
    "    },  # configuration for autogen's enhanced inference API which is compatible with OpenAI API\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    max_consecutive_auto_reply=1,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"coding\",\n",
    "        \"use_docker\": False,  # set to True or image name like \"python:3\" to use docker\n",
    "    },\n",
    ")\n",
    "user_proxy.initiate_chat(\n",
    "    recipient=assistant,\n",
    "    message=PROMPT + ADDITIONAL_PROMPT,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
